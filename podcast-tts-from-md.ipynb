{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0b6ac-5f02-418d-ba1b-03a2766dbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 1: Fetch markdown from GitHub and inject Agentic AI intro section\n",
    "\n",
    "import requests\n",
    "\n",
    "# ‚úÖ Correct raw GitHub markdown URL\n",
    "url = \"https://raw.githubusercontent.com/PrabuAppDev/github-pages-genai/main/crew-ai-multi-agents.md\"\n",
    "\n",
    "# Fetch content\n",
    "response = requests.get(url)\n",
    "original_md = response.text\n",
    "\n",
    "# Agentic AI introduction paragraph\n",
    "agentic_intro = (\n",
    "    \"## Introduction to Agentic AI\\n\\n\"\n",
    "    \"Agentic AI is the next evolution beyond Retrieval-Augmented Generation (RAG). \"\n",
    "    \"Rather than relying on a single model to answer questions from documents, \"\n",
    "    \"Agentic AI orchestrates multiple specialized LLM agents, each with a defined role. \"\n",
    "    \"These agents operate in a response ‚Üí action loop, interacting with tools like OCR engines, databases, or APIs \"\n",
    "    \"to complete complex workflows autonomously.\\n\\n\"\n",
    ")\n",
    "\n",
    "# Insert intro after front matter (--- blocks)\n",
    "parts = original_md.split('---')\n",
    "if len(parts) >= 3:\n",
    "    parts[2] = \"\\n\" + agentic_intro + parts[2]\n",
    "    updated_md = '---'.join(parts)\n",
    "else:\n",
    "    updated_md = agentic_intro + original_md  # Fallback if no front matter\n",
    "\n",
    "# Show preview\n",
    "print(\"\\n\".join(updated_md.strip().splitlines()[:20]))  # Show first 20 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5009364-2b0a-49b7-b8da-707ed83877ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 2: Strip markdown formatting to prepare plain narration text\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def markdown_to_narration_text(md_text):\n",
    "    # Remove front matter if still present\n",
    "    if md_text.startswith('---'):\n",
    "        md_text = re.split(r'^---$', md_text, flags=re.MULTILINE)[-1]\n",
    "\n",
    "    # Remove Markdown links but keep link text\n",
    "    md_text = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1', md_text)\n",
    "\n",
    "    # Remove HTML tags (e.g., <a href=...>)\n",
    "    md_text = BeautifulSoup(md_text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove bold/italic markers\n",
    "    md_text = re.sub(r'[_*`#~]', '', md_text)\n",
    "\n",
    "    # Replace bullet points and headings with newlines\n",
    "    md_text = re.sub(r'^\\s*[-*+]\\s+', '\\n‚Ä¢ ', md_text, flags=re.MULTILINE)\n",
    "    md_text = re.sub(r'^#{1,6}\\s*', '\\n', md_text, flags=re.MULTILINE)\n",
    "\n",
    "    # Collapse multiple newlines\n",
    "    md_text = re.sub(r'\\n{2,}', '\\n\\n', md_text)\n",
    "\n",
    "    return md_text.strip()\n",
    "\n",
    "# Clean narration text\n",
    "narration_text = markdown_to_narration_text(updated_md)\n",
    "\n",
    "# Show a short preview\n",
    "print(\"\\n\".join(narration_text.splitlines()[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c659e5-ab36-4d74-9865-43fe839ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 3: Convert voiceover intro text to male audio using OpenAI TTS (voice: echo)\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# üîê Ensure your API key is loaded securely via environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Voiceover script\n",
    "intro_text = (\n",
    "    \"Hi, I‚Äôm the AI voice of Prabu Arumugam. Trusted technology advisor with experience in systems architecture and software engineering. \"\n",
    "    \"Specialized in large-scale systems transformations for the property and casualty insurance industry. \"\n",
    "    \"I‚Äôm a pragmatic problem-solver with a proven track record of delivering results. \"\n",
    "    \"With over 20 years of experience in P&C core systems and digital transformation ‚Äî covering data migration, \"\n",
    "    \"underwriting, pricing, rating, and policy administration ‚Äî I bring expertise in solution architecture and systems modernization \"\n",
    "    \"for P&C core applications and digital innovation.\"\n",
    ")\n",
    "\n",
    "# Generate and save MP3\n",
    "speech_response = openai.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"echo\",  # Male voice\n",
    "    input=intro_text\n",
    ")\n",
    "\n",
    "# Save audio file\n",
    "with open(\"intro_prabu.mp3\", \"wb\") as f:\n",
    "    f.write(speech_response.content)\n",
    "\n",
    "print(\"‚úÖ Voiceover saved as 'intro_prabu.mp3'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79409a-6da5-4714-ae1a-e63bcca31c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 4: Embed the generated voiceover MP3 using an HTML audio tag in the markdown\n",
    "\n",
    "# Define the audio player HTML\n",
    "audio_embed_html = (\n",
    "    '\\n<audio controls>\\n'\n",
    "    '  <source src=\"intro_prabu.mp3\" type=\"audio/mpeg\">\\n'\n",
    "    '  Your browser does not support the audio element.\\n'\n",
    "    '</audio>\\n\\n'\n",
    ")\n",
    "\n",
    "# Inject after the Agentic AI intro (we'll use its heading to locate insert point)\n",
    "inject_point = \"## Introduction to Agentic AI\"\n",
    "if inject_point in updated_md:\n",
    "    updated_md_with_audio = updated_md.replace(inject_point, f\"{inject_point}\\n\\n{audio_embed_html}\", 1)\n",
    "else:\n",
    "    updated_md_with_audio = audio_embed_html + updated_md  # Fallback if not found\n",
    "\n",
    "# Save to new markdown file\n",
    "output_md_path = \"crew-ai-with-audio.md\"\n",
    "with open(output_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(updated_md_with_audio)\n",
    "\n",
    "print(f\"‚úÖ Markdown with embedded audio saved as '{output_md_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95703465-5db6-4304-8603-7e5c147138e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 5: Split narration text into sections for TTS processing\n",
    "\n",
    "import textwrap\n",
    "\n",
    "# Use the cleaned narration text from Cell 2\n",
    "lines = narration_text.splitlines()\n",
    "\n",
    "# Group lines into sections based on H2/H3-style headings (e.g., Crew AI, Agents, Workflow, etc.)\n",
    "sections = []\n",
    "current_section = []\n",
    "\n",
    "for line in lines:\n",
    "    if line.strip().startswith(\"##\") or line.strip().startswith(\"###\"):\n",
    "        if current_section:\n",
    "            sections.append(\"\\n\".join(current_section).strip())\n",
    "            current_section = []\n",
    "    current_section.append(line)\n",
    "\n",
    "# Append the final section\n",
    "if current_section:\n",
    "    sections.append(\"\\n\".join(current_section).strip())\n",
    "\n",
    "# Wrap paragraphs for easier debugging/printing\n",
    "for idx, section in enumerate(sections):\n",
    "    print(f\"\\nüß© Section {idx + 1}\\n\" + \"-\"*20)\n",
    "    print(textwrap.shorten(section.replace(\"\\n\", \" \"), width=300, placeholder=\"...\"))\n",
    "\n",
    "# Show number of sections\n",
    "print(f\"\\n‚úÖ Total sections prepared for TTS: {len(sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ea9a2-91ef-4e9b-92c5-63fe642dae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 7: Embed Section 1 MP3 audio player after its heading in the markdown\n",
    "\n",
    "# Define HTML audio block\n",
    "section_audio_html = (\n",
    "    '\\n<audio controls>\\n'\n",
    "    '  <source src=\"section_1.mp3\" type=\"audio/mpeg\">\\n'\n",
    "    '  Your browser does not support the audio element.\\n'\n",
    "    '</audio>\\n\\n'\n",
    ")\n",
    "\n",
    "# Find the insertion point again\n",
    "injection_heading = \"## Introduction to Agentic AI\"\n",
    "\n",
    "# Inject the player just after the heading\n",
    "if injection_heading in updated_md_with_audio:\n",
    "    updated_md_with_section_audio = updated_md_with_audio.replace(\n",
    "        injection_heading,\n",
    "        f\"{injection_heading}\\n\\n{section_audio_html}\",\n",
    "        1\n",
    "    )\n",
    "else:\n",
    "    # Fallback if heading not found\n",
    "    updated_md_with_section_audio = section_audio_html + updated_md_with_audio\n",
    "\n",
    "# Save to a new markdown file\n",
    "final_md_path = \"crew-ai-with-section1-audio.md\"\n",
    "with open(final_md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(updated_md_with_section_audio)\n",
    "\n",
    "print(f\"‚úÖ Final markdown with Section 1 audio saved as '{final_md_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e309cb-e55b-4292-a14d-8d48fb1655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 8: Re-split original markdown into sections based on raw headings (##, ###)\n",
    "\n",
    "def split_markdown_by_headings(md_text, heading_level=\"##\"):\n",
    "    lines = md_text.splitlines()\n",
    "    sections = []\n",
    "    current_section = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(heading_level):\n",
    "            if current_section:\n",
    "                sections.append(\"\\n\".join(current_section).strip())\n",
    "                current_section = []\n",
    "        current_section.append(line)\n",
    "\n",
    "    if current_section:\n",
    "        sections.append(\"\\n\".join(current_section).strip())\n",
    "\n",
    "    return sections\n",
    "\n",
    "# Use updated_md_with_audio which includes Agentic AI intro\n",
    "raw_md_sections = split_markdown_by_headings(updated_md_with_audio, heading_level=\"##\")\n",
    "\n",
    "# Preview headings + count\n",
    "for i, sec in enumerate(raw_md_sections):\n",
    "    heading = sec.strip().splitlines()[0].strip()\n",
    "    print(f\"üß© Section {i+1}: {heading}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total sections detected: {len(raw_md_sections)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b12e1f-83aa-44f6-9cf9-4490dbf55a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the exact TTS input\n",
    "for idx in range(2, len(raw_md_sections)):\n",
    "    section_text = markdown_to_narration_text(raw_md_sections[idx])\n",
    "    print(f\"\\nüìù TTS Input for Section {idx}:\\n{section_text[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c1f44-2f27-45bf-a36e-2477fc6f796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå FIXED Cell 10: Generate audio correctly without HTML issues\n",
    "\n",
    "import time\n",
    "\n",
    "start_index = 1\n",
    "total_sections = len(raw_md_sections)\n",
    "\n",
    "overall_start = time.time()\n",
    "\n",
    "for idx in range(start_index, total_sections):\n",
    "    section = raw_md_sections[idx]\n",
    "    display_index = idx  \n",
    "\n",
    "    section_start = time.time()\n",
    "\n",
    "    # ‚úÖ Ensure we only send clean narration text (NO HTML)\n",
    "    clean_text = markdown_to_narration_text(section)\n",
    "\n",
    "    # Truncate overly long sections (just in case)\n",
    "    if len(clean_text) > 4096:\n",
    "        print(f\"‚ö†Ô∏è Truncating Section {display_index} to 4096 characters.\")\n",
    "        clean_text = clean_text[:4096]\n",
    "\n",
    "    print(f\"\\nüéôÔ∏è [Section {display_index}/{total_sections}] Generating TTS...\")\n",
    "\n",
    "    try:\n",
    "        response = openai.audio.speech.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"echo\",\n",
    "            input=clean_text  # ‚úÖ Ensure no HTML is sent\n",
    "        )\n",
    "\n",
    "        filename = f\"section_{display_index}.mp3\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        elapsed = time.time() - section_start\n",
    "        print(f\"‚úÖ Saved: {filename} (‚è± {elapsed:.2f} sec)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating Section {display_index}: {e}\")\n",
    "\n",
    "overall_elapsed = time.time() - overall_start\n",
    "print(f\"\\n‚è≥ All sections processed in {overall_elapsed:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b87010-bc40-440a-a61a-d3c81ca8cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List all generated MP3s\n",
    "audio_files = [f for f in os.listdir() if f.endswith(\".mp3\")]\n",
    "\n",
    "# Verify file sizes\n",
    "for file in audio_files:\n",
    "    size = os.path.getsize(file)\n",
    "    print(f\"üéµ {file}: {size / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035b773-ff31-4523-8f86-87ad472d7835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Delete only the corrupted section_1.mp3 file\n",
    "if os.path.exists(\"section_1.mp3\"):\n",
    "    os.remove(\"section_1.mp3\")\n",
    "    print(\"üóë Deleted corrupted section_1.mp3\")\n",
    "\n",
    "# Use OpenAI TTS to regenerate\n",
    "import openai\n",
    "\n",
    "# Ensure your API key is set\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get the correct clean text for section_1\n",
    "section_1_text = markdown_to_narration_text(raw_md_sections[1])  # Section 1 (Index 1)\n",
    "\n",
    "# Regenerate speech\n",
    "response = openai.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"echo\",\n",
    "    input=section_1_text\n",
    ")\n",
    "\n",
    "# Ensure we are saving actual MP3 binary data\n",
    "if hasattr(response, 'content'):\n",
    "    with open(\"section_1.mp3\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"‚úÖ Successfully regenerated section_1.mp3\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: OpenAI did not return audio for section_1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d5daa-186f-4de2-9dff-7d12b3fc2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå DEBUG: Verify Cleaned Section 1 (Before Sending to OpenAI)\n",
    "\n",
    "section_1_text = markdown_to_narration_text(raw_md_sections[1])  # Section 1\n",
    "print(\"\\nüìù CLEANED TTS Input for Section 1 (First 500 chars):\\n\", section_1_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939770b-8393-4648-952b-d1dbe82fe362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no unwanted text remains in Section 1\n",
    "section_1_text = section_1_text.replace(\"Your browser does not support the audio element.\", \"\").strip()\n",
    "\n",
    "# Debug again\n",
    "print(\"\\nüìù FINAL CLEANED TTS Input for Section 1 (First 500 chars):\\n\", section_1_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96cbc3-2d68-4255-b666-ad213a859d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå DEBUG: Check OpenAI's response for section_1 before saving\n",
    "\n",
    "import openai\n",
    "\n",
    "# Fetch the clean text again\n",
    "section_1_text = markdown_to_narration_text(raw_md_sections[1])  # Section 1\n",
    "\n",
    "print(\"\\nüìù Checking OpenAI TTS Input (First 500 chars):\\n\", section_1_text[:500])\n",
    "\n",
    "# Generate speech\n",
    "response = openai.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"echo\",\n",
    "    input=section_1_text\n",
    ")\n",
    "\n",
    "# üõ† DEBUG: Check if response contains audio or text\n",
    "print(\"\\nüîç OpenAI API Response Type:\", type(response))\n",
    "print(\"\\nüîç OpenAI API Response Content (First 500 chars):\\n\", response.content[:500])\n",
    "\n",
    "# Check response headers to confirm it's MP3\n",
    "print(\"\\nüîç OpenAI API Response Headers:\", response.headers if hasattr(response, 'headers') else \"No headers available\")\n",
    "\n",
    "# Play the response (if valid audio)\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136472a4-950f-4028-9bef-ae4b5e19ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no unwanted text remains in Section 1\n",
    "section_1_text = section_1_text.replace(\"Your browser does not support the audio element.\", \"\").strip()\n",
    "\n",
    "# Debug again\n",
    "print(\"\\nüìù FINAL CLEANED TTS Input for Section 1 (First 500 chars):\\n\", section_1_text[:500])\n",
    "\n",
    "# üìå Generate Clean TTS for Section 1\n",
    "\n",
    "response = openai.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"echo\",\n",
    "    input=section_1_text\n",
    ")\n",
    "\n",
    "# Save new MP3\n",
    "if hasattr(response, 'content') and isinstance(response.content, bytes):\n",
    "    with open(\"section_1.mp3\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"‚úÖ Successfully regenerated CLEAN section_1.mp3\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI did NOT return valid speech. Check the API response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fd484-472e-4a78-bbc7-8a1a4c844f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Select one of the MP3 files\n",
    "sample_mp3 = \"section_1.mp3\"  # Change to another file if needed\n",
    "\n",
    "# Play audio to verify if the issue exists\n",
    "print(f\"üîç Playing: {sample_mp3}\")\n",
    "ipd.Audio(sample_mp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1fc05-2645-4409-aa65-c10241295f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 11: Embed all section audio players and save as 'podcast-on-agentic-crew-ai.md'\n",
    "\n",
    "# Start with markdown containing Agentic AI intro\n",
    "final_md = updated_md\n",
    "\n",
    "# Audio embed helper\n",
    "def audio_html(filename):\n",
    "    return (\n",
    "        f'\\n<audio controls>\\n'\n",
    "        f'  <source src=\"./{filename}\" type=\"audio/mpeg\">\\n'\n",
    "        f'  Your browser does not support the audio element.\\n'\n",
    "        f'</audio>\\n'\n",
    "    )\n",
    "\n",
    "# Inject audio after each heading based on section titles\n",
    "for idx in range(2, len(raw_md_sections)):\n",
    "    section_heading_line = raw_md_sections[idx].splitlines()[0].strip()\n",
    "    heading_text = re.sub(r'^#+\\s*', '', section_heading_line)\n",
    "    pattern = re.compile(rf\"^(#+\\s*{re.escape(heading_text)})\", re.MULTILINE)\n",
    "    final_md = pattern.sub(rf\"\\1\\n{audio_html(f'section_{idx}.mp3')}\", final_md)\n",
    "\n",
    "# Inject your intro after \"Introduction to Agentic AI\"\n",
    "final_md = final_md.replace(\n",
    "    \"## Introduction to Agentic AI\",\n",
    "    \"## Introduction to Agentic AI\\n\" + audio_html(\"intro_prabu.mp3\"),\n",
    "    1\n",
    ")\n",
    "\n",
    "# Save to renamed markdown file\n",
    "final_output_path = \"podcast-on-agentic-crew-ai.md\"\n",
    "with open(final_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_md)\n",
    "\n",
    "print(f\"‚úÖ Final podcast markdown saved as '{final_output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdba0cd-5d21-45a4-a760-5f5ec31d65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 12 (fixed): Generate Podcast Q&A using new OpenAI Python SDK format\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client using API key from environment\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Combine relevant markdown sections for the podcast\n",
    "sections_to_include = [1, 2, 5, 6, 7, 10, 11]  # Indexes from raw_md_sections\n",
    "combined_text = \"\\n\\n\".join(markdown_to_narration_text(raw_md_sections[i]) for i in sections_to_include)\n",
    "\n",
    "# Prompt definition\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a podcast producer converting technical documentation into a natural, engaging interview script between a host and an expert named Prabu Arumugam.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "Turn the following documentation into a podcast-style Q&A. Include:\n",
    "- An intro from the host\n",
    "- A greeting and personal intro from Prabu (as already recorded)\n",
    "- Conversational tone (not robotic)\n",
    "- Questions from host followed by expert answers\n",
    "\n",
    "Keep responses concise and engaging. Here is the content:\n",
    "\n",
    "{combined_text}\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Extract the script\n",
    "podcast_script = response.choices[0].message.content.strip()\n",
    "\n",
    "# Print preview (first 2000 characters)\n",
    "print(podcast_script[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7d713-94f6-4ea9-b2ae-fc54879f0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Cell 13 (fixed): Safely split podcast script into speaker segments\n",
    "\n",
    "segments = []\n",
    "lines = podcast_script.strip().splitlines()\n",
    "\n",
    "current_speaker = None\n",
    "current_text = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Host:\"):\n",
    "        if current_text:\n",
    "            segments.append({\n",
    "                \"speaker\": current_speaker or \"narration\",\n",
    "                \"text\": \" \".join(current_text)\n",
    "            })\n",
    "            current_text = []\n",
    "        current_speaker = \"host\"\n",
    "        current_text.append(line.replace(\"Host:\", \"\").strip())\n",
    "    elif line.startswith(\"Prabu:\"):\n",
    "        if current_text:\n",
    "            segments.append({\n",
    "                \"speaker\": current_speaker or \"narration\",\n",
    "                \"text\": \" \".join(current_text)\n",
    "            })\n",
    "            current_text = []\n",
    "        current_speaker = \"prabu\"\n",
    "        current_text.append(line.replace(\"Prabu:\", \"\").strip())\n",
    "    else:\n",
    "        current_text.append(line)\n",
    "\n",
    "# Append last collected segment\n",
    "if current_text:\n",
    "    segments.append({\n",
    "        \"speaker\": current_speaker or \"narration\",\n",
    "        \"text\": \" \".join(current_text)\n",
    "    })\n",
    "\n",
    "# Display preview\n",
    "for i, seg in enumerate(segments):\n",
    "    speaker = seg[\"speaker\"]\n",
    "    preview = seg[\"text\"][:80].strip()\n",
    "    print(f\"[{i+1}] üéôÔ∏è {speaker.title()} says: {preview}...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total segments: {len(segments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f3ee8-4936-45c5-9989-49e33d854cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Define voice mapping\n",
    "voice_map = {\n",
    "    \"narration\": \"echo\",  # Neutral voice for narration\n",
    "    \"host\": \"nova\",       # Friendly voice for host\n",
    "    \"prabu\": \"onyx\"       # Authoritative, deeper voice for Prabu\n",
    "}\n",
    "\n",
    "# Ensure podcast_script is properly populated with the podcast text\n",
    "podcast_script = \"\"\"Host: Hello and welcome to today's podcast!\n",
    "Prabu: Thanks for having me, it's a pleasure to be here.\n",
    "Host: Today we will talk about Agentic AI.\n",
    "Prabu: Absolutely, let's dive right into it.\n",
    "Host: Can you explain what Agentic AI is?\n",
    "Prabu: Of course, Agentic AI is the next evolution in AI technology.\n",
    "Host: That sounds interesting, tell us more.\n",
    "Prabu: Sure, it works by coordinating specialized agents to work together autonomously.\"\"\"\n",
    "\n",
    "# Split the podcast script into segments based on speakers (Host and Prabu)\n",
    "segments = []\n",
    "lines = podcast_script.strip().splitlines()\n",
    "\n",
    "current_speaker = None\n",
    "current_text = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Host:\"):\n",
    "        if current_text:\n",
    "            segments.append({\n",
    "                \"speaker\": current_speaker or \"narration\",\n",
    "                \"text\": \" \".join(current_text)\n",
    "            })\n",
    "            current_text = []\n",
    "        current_speaker = \"host\"\n",
    "        current_text.append(line.replace(\"Host:\", \"\").strip())\n",
    "    elif line.startswith(\"Prabu:\"):\n",
    "        if current_text:\n",
    "            segments.append({\n",
    "                \"speaker\": current_speaker or \"narration\",\n",
    "                \"text\": \" \".join(current_text)\n",
    "            })\n",
    "            current_text = []\n",
    "        current_speaker = \"prabu\"\n",
    "        current_text.append(line.replace(\"Prabu:\", \"\").strip())\n",
    "    else:\n",
    "        current_text.append(line)\n",
    "\n",
    "# Append the last collected segment\n",
    "if current_text:\n",
    "    segments.append({\n",
    "        \"speaker\": current_speaker or \"narration\",\n",
    "        \"text\": \" \".join(current_text)\n",
    "    })\n",
    "\n",
    "# Display preview of segments\n",
    "for i, seg in enumerate(segments):\n",
    "    speaker = seg[\"speaker\"]\n",
    "    preview = seg[\"text\"][:80].strip()\n",
    "    print(f\"[{i+1}] üéôÔ∏è {speaker.title()} says: {preview}...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total segments: {len(segments)}\")\n",
    "\n",
    "# Now generate TTS MP3 for each segment and save them\n",
    "output_dir = \"tts_segments\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through segments and generate TTS for each\n",
    "for i, seg in enumerate(segments, 1):\n",
    "    speaker = seg[\"speaker\"]\n",
    "    text = seg[\"text\"].strip()  # Clean up the text to avoid extra spaces or empty segments\n",
    "    \n",
    "    if not text:\n",
    "        print(f\"‚ùå Skipping segment {i}: No text available.\")\n",
    "        continue  # Skip empty segments\n",
    "\n",
    "    voice = voice_map.get(speaker, \"echo\")  # Default to \"echo\" if no voice found\n",
    "    filename = f\"podcast_segment_{i:03d}_{speaker}.mp3\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    print(f\"üé§ [{i}/{len(segments)}] Generating {filename} with voice '{voice}'...\")\n",
    "\n",
    "    try:\n",
    "        # Generate the TTS response from OpenAI API\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"tts-1-hd\",  # Use the TTS model\n",
    "            voice=voice,       # Select the voice based on the speaker\n",
    "            input=text         # Pass the text for conversion to speech\n",
    "        )\n",
    "\n",
    "        # Save the generated audio to the file\n",
    "        if 'data' in response:\n",
    "            # Ensure the response data is being written to the file as binary content\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response['data'])\n",
    "            print(f\"‚úÖ {filename} saved successfully!\")\n",
    "        else:\n",
    "            print(f\"‚ùå No audio content in the response for segment {i}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating {filename}: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ All segments processed. Audio files saved in:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
